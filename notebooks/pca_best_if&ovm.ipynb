{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# be careful with that:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, confusion_matrix, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, adjusted_rand_score, precision_recall_curve, precision_score, f1_score\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "from scipy.stats import uniform, chisquare, binomtest\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID ID = 333346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid ID:  333346\n",
      "Nb components:  200\n",
      "Data directory:  ../datasets/train/data_heatmap_train.csv\n"
     ]
    }
   ],
   "source": [
    "# Train Data\n",
    "!python3 pca_pipeline.py 333346 200 '../datasets/train/data_heatmap_train.csv'\n",
    "grid_id = 333346\n",
    "\n",
    "import pandas as pd\n",
    "pca_df = pd.read_csv('temp/pca_df.csv')\n",
    "normalized_input = pd.read_csv('temp/normalized_input.csv')\n",
    "#X_train = normalized_input.iloc[:,2:-1]\n",
    "#y_train = normalized_input.iloc[:,-1]\n",
    "pca_df = pca_df.iloc[:,1:]\n",
    "pca_df_inp = pca_df.iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid ID:  333346\n",
      "Nb components:  200\n",
      "Data directory:  ../datasets/test/data_heatmap_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Test Data\n",
    "!python3 pca_pipeline.py 333346 200 '../datasets/test/data_heatmap_test.csv'\n",
    "grid_id = 333346\n",
    "\n",
    "import pandas as pd\n",
    "pca_df_test = pd.read_csv('temp/pca_df.csv')\n",
    "normalized_input_test = pd.read_csv('temp/normalized_input.csv')\n",
    "#X_train = normalized_input.iloc[:,2:-1]\n",
    "#y_train = normalized_input.iloc[:,-1]\n",
    "\n",
    "pca_df_test = pca_df_test.iloc[:,1:]\n",
    "pca_df_inp_test = pca_df_test.iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acutal label\n",
    "y = pca_df_test[['label']].values\n",
    "#y = pca_df_test['label'].values\n",
    "#y = pca_df[['label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for 85 PCA dimensions:\n",
      "  [[ 67 158]\n",
      " [  0  34]]\n",
      "F1 Score for 85 PCA dimensions:  0.30\n"
     ]
    }
   ],
   "source": [
    "# Best Model is with 85 PCA dimensions\n",
    "pca_dim = 85\n",
    "\n",
    "X_train = pca_df_inp.iloc[:,:pca_dim]\n",
    "X_test = pca_df_inp_test.iloc[:,:pca_dim]\n",
    "\n",
    "oneclass = OneClassSVM(gamma = 'auto').fit(X_train)\n",
    "oneclass_labels = oneclass.predict(X_test)\n",
    "    \n",
    "oneclass_labels = np.where(oneclass_labels == 1, 0,1)\n",
    "conf_mat   = confusion_matrix(y,oneclass_labels)\n",
    "acc        = accuracy_score(y,oneclass_labels)\n",
    "recall     = recall_score(y,oneclass_labels)\n",
    "prec       = precision_score(y,oneclass_labels)\n",
    "f1         = f1_score(y,oneclass_labels)\n",
    "\n",
    "print(f'Confusion matrix for {pca_dim} PCA dimensions:\\n', \n",
    "              f' {conf_mat}')\n",
    "#print(f'Accuracy for {pca_dim} PCA dimensions:', \n",
    "#              f' {acc:.2f}')\n",
    "#print(f'Recall for {pca_dim} PCA dimensions:', \n",
    "#              f' {recall:.2f}')\n",
    "#print(f'Precision for {pca_dim} PCA dimensions:', \n",
    "#              f' {prec:.2f}')\n",
    "print(f'F1 Score for {pca_dim} PCA dimensions:', \n",
    "              f' {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for 6 PCA dimensions:\n",
      "  [[223   2]\n",
      " [  1  33]]\n",
      "F1 Score for 6 PCA dimensions with n_estimator = 50:  0.96\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "#Best Model for Isolation Forest is with 6 PCA and n_estimators = 50\n",
    "best_n_est = 50\n",
    "pca_dim = 6\n",
    "X_train = pca_df_inp.iloc[:,:pca_dim]\n",
    "X_test = pca_df_inp_test.iloc[:,:pca_dim]\n",
    "            \n",
    "isolation_forest = IsolationForest(n_estimators=best_n_est, \n",
    "                                   max_samples='auto', \n",
    "                                   random_state=42)\n",
    "\n",
    "model = isolation_forest.fit(X_train)\n",
    "if_labels = model.predict(X_test)\n",
    "if_labels = np.where(if_labels == -1, 1, 0)\n",
    "\n",
    "conf_mat   = confusion_matrix(y,if_labels)\n",
    "acc        = accuracy_score(y,if_labels)\n",
    "recall     = recall_score(y,if_labels)\n",
    "prec       = precision_score(y,if_labels)\n",
    "f1         = f1_score(y, if_labels)\n",
    "\n",
    "\n",
    "print(f'Confusion matrix for {pca_dim} PCA dimensions:\\n', \n",
    "                      f' {conf_mat}')\n",
    "#print(f'Accuracy for {pca_dim} PCA dimensions:', \n",
    "#                      f' {acc:.2f}')\n",
    "#print(f'Recall for {pca_dim} PCA dimensions:', \n",
    "#                      f' {recall:.2f}')\n",
    "#print(f'Precision for {pca_dim} PCA dimensions:', \n",
    "#                      f' {prec:.2f}')\n",
    "print(f'F1 Score for {pca_dim} PCA dimensions with n_estimator = {best_n_est}:', \n",
    "                      f' {f1:.2f}')\n",
    "print(f'---------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID ID = 333519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid ID:  333519\n",
      "Nb components:  200\n",
      "Data directory:  ../datasets/train/data_heatmap_train.csv\n"
     ]
    }
   ],
   "source": [
    "!python3 pca_pipeline.py 333519 200 '../datasets/train/data_heatmap_train.csv'\n",
    "grid_id = 333519\n",
    "\n",
    "import pandas as pd\n",
    "pca_df = pd.read_csv('temp/pca_df.csv')\n",
    "normalized_input = pd.read_csv('temp/normalized_input.csv')\n",
    "# X_train = normalized_input.iloc[:,2:-1]\n",
    "# y_train = normalized_input.iloc[:,-1]\n",
    "\n",
    "pca_df = pca_df.iloc[:,1:]\n",
    "pca_df_inp = pca_df.iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid ID:  333519\n",
      "Nb components:  200\n",
      "Data directory:  ../datasets/test/data_heatmap_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Test Data\n",
    "!python3 pca_pipeline.py 333519 200 '../datasets/test/data_heatmap_test.csv'\n",
    "grid_id = 333519\n",
    "\n",
    "import pandas as pd\n",
    "pca_df_test = pd.read_csv('temp/pca_df.csv')\n",
    "normalized_input_test = pd.read_csv('temp/normalized_input.csv')\n",
    "#X_train = normalized_input.iloc[:,2:-1]\n",
    "#y_train = normalized_input.iloc[:,-1]\n",
    "\n",
    "pca_df_test = pca_df_test.iloc[:,1:]\n",
    "pca_df_inp_test = pca_df_test.iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acutal label\n",
    "y = pca_df_test[['label']].values\n",
    "#y = pca_df_test['label'].values\n",
    "#y = pca_df[['label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for 85 PCA dimensions:\n",
      "  [[ 61 184]\n",
      " [  0  17]]\n",
      "F1 Score for 85 PCA dimensions:  0.16\n"
     ]
    }
   ],
   "source": [
    "# Best Model is with 163 PCA dimensions\n",
    "# Best Model is with 85 PCA dimensions\n",
    "pca_dim = 85\n",
    "\n",
    "X_train = pca_df_inp.iloc[:,:pca_dim]\n",
    "X_test = pca_df_inp_test.iloc[:,:pca_dim]\n",
    "\n",
    "oneclass = OneClassSVM(gamma = 'auto').fit(X_train)\n",
    "oneclass_labels = oneclass.predict(X_test)\n",
    "    \n",
    "oneclass_labels = np.where(oneclass_labels == 1, 0,1)\n",
    "conf_mat   = confusion_matrix(y,oneclass_labels)\n",
    "acc        = accuracy_score(y,oneclass_labels)\n",
    "recall     = recall_score(y,oneclass_labels)\n",
    "prec       = precision_score(y,oneclass_labels)\n",
    "f1         = f1_score(y,oneclass_labels)\n",
    "\n",
    "print(f'Confusion matrix for {pca_dim} PCA dimensions:\\n', \n",
    "              f' {conf_mat}')\n",
    "#print(f'Accuracy for {pca_dim} PCA dimensions:', \n",
    "#              f' {acc:.2f}')\n",
    "#print(f'Recall for {pca_dim} PCA dimensions:', \n",
    "#              f' {recall:.2f}')\n",
    "#print(f'Precision for {pca_dim} PCA dimensions:', \n",
    "#              f' {prec:.2f}')\n",
    "print(f'F1 Score for {pca_dim} PCA dimensions:', \n",
    "              f' {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for 10 PCA dimensions:\n",
      "  [[225  20]\n",
      " [  1  16]]\n",
      "F1 Score for 10 PCA dimensions with n_estimator = 100:  0.60\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "#Best Model for Isolation Forest is with 10 PCA and n_estimators = 100\n",
    "best_n_est = 100\n",
    "pca_dim = 10\n",
    "X_train = pca_df_inp.iloc[:,:pca_dim]\n",
    "X_test = pca_df_inp_test.iloc[:,:pca_dim]\n",
    "            \n",
    "isolation_forest = IsolationForest(n_estimators=best_n_est, \n",
    "                                   max_samples='auto', \n",
    "                                   random_state=42)\n",
    "\n",
    "model = isolation_forest.fit(X_train)\n",
    "if_labels = model.predict(X_test)\n",
    "if_labels = np.where(if_labels == -1, 1, 0)\n",
    "\n",
    "conf_mat   = confusion_matrix(y,if_labels)\n",
    "acc        = accuracy_score(y,if_labels)\n",
    "recall     = recall_score(y,if_labels)\n",
    "prec       = precision_score(y,if_labels)\n",
    "f1         = f1_score(y, if_labels)\n",
    "\n",
    "\n",
    "print(f'Confusion matrix for {pca_dim} PCA dimensions:\\n', \n",
    "                      f' {conf_mat}')\n",
    "#print(f'Accuracy for {pca_dim} PCA dimensions:', \n",
    "#                      f' {acc:.2f}')\n",
    "#print(f'Recall for {pca_dim} PCA dimensions:', \n",
    "#                      f' {recall:.2f}')\n",
    "#print(f'Precision for {pca_dim} PCA dimensions:', \n",
    "#                      f' {prec:.2f}')\n",
    "print(f'F1 Score for {pca_dim} PCA dimensions with n_estimator = {best_n_est}:', \n",
    "                      f' {f1:.2f}')\n",
    "print(f'---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
